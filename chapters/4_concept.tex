% Chapter 4 is usually termed 'Concept', 'Design' or 'Model'. Here you describe your approach, give a
% high-level description to the architectural structure and to the single components that your solution
% consists of. Use structured images and UML diagrams for explanation. This chapter will have a volume
% of 20-30 percent of your thesis.
%
% This chapter introduces the architectural design of Component X. The component consists of
% subcomponent A, B and C.
%
% In the end of this chapter you should write a specification for your solution, including
% interfaces, protocols and parameters.

\chapter{Concept\label{cha:concept}}

This section will explain in more details the concepts of each individual component and how they
play together. Each component individually contributes to the overall goal of implementing a
development and test automation platform to build HbbTV applications. Starting with the base
component the Devtools Backend service which will help use to with the first part of the goal.
It enables new possibilities for devs to inspect an HbbTV app and understand and debug JavaScript
problems within their code. It helps us to instrument the application to run automated WebDriver
tests with the Appium HbbTV Driver. It acts as translator between the WebDriver protocol
and the Remote Debugging Protocol. To do that on a bigger scale we need the Raspberry Pi to deploy
that driver to any TV without any manual steps. To manage all these driver we then use a Selenium
Grid and with a proper CI/CD server we can leverage that setup to test and release our HbbTV apps
faster and with more confidence.

\section{Components\label{sec:components}}

\subsection{Devtools Backend\label{sec:devtoolsbackend}}

The Devtools Backend is the main component of the overall design. It has to do most of the work and
is the only component that directly interacts with the targeted environment: the HbbTV application.
Debugging an HbbTV application these days is almost impossible. Even though some TV manufactures
provide some interfaces and APIs to connect to the TV they are hardly documented and almost different
for each TV model. To provide a tool that covers all TVs of all manufactures requires a different
approach than hooking into a native interface. Until all manufactures recognize the demand for
developers to get a better development support this won't change. We already had a similar situation
almost 7 years ago when the smart phone market started to explode and a lot of people started writing
web apps or hybrid apps for Android and iOS. At that time both vendors had almost no support for
any debugging tools that would help developers to inspect the page. A tool called \textit{Weinre}
\footnote{WEb INspector REmote - \url{http://people.apache.org/~pmuellr/weinre/docs/latest/Home.html}}
was developed and found a lot of popularity within the developer community. It enabled to debug web
pages remotely, especially on a mobile device such as a phone, for the first time. It used a special
approach that allowed to do that not only for but for all mobile environments (Android, iOS and
Hybrid web applications run by PhoneGap/Cordova). After vendors started to support remote debugging
natively due to the success of this project it became obsolete and the inventor stopped maintaining
it.

This project is the role model for the Devtools Backend. Similar how it allowed remote debug apps
for smart phones the Devtools Backend will allow it to do so with HbbTV apps on smart TVs. The idea
is simple. A script that gets executed within a targeted environment connects to a server to
exchange information and commands as utility for a 3rd party authoring tool. The concept works
independant from the environment and device. As long as the target supports basic web technology
like HTML and JavaScript it will run everywhere. So this component can not only be used to debug HbbTV
apps on Smart TVs but also to inspect any other IoT device like a fridge or a coffee machine as long
as their interfaces are based on web technologies\footnote{Infact the screen in the Tesla Model S
is build on top of a proparitary web browser and therefor all Tesla apps are build with web
technology. Theoretically the Devtools Backend can be used to debug these apps with modern web
authoring tools already today.} \footnote{An example application can be found here: \url{http://dash.time4tesla.com/}}.

The component itself consists of two subcomponents. Similar to \textit{Weinre} it has a frontend
part that takes care on instrumenting the target environment and a backend part which is a server
that initializes and manages the data traffic between target environment and authoring tool. Both
subcomponents have logic to handle methods or trigger events according to the Remote Debugging
Protocol. As stated in section \ref{sec:remotedebuggingprotocol} the Remote Debugging Protocol is
supported by all WebKit browser and has first class support for one of the most used web authoring
tools these days: the Chrome Devtools. In addition to that it is actively maintained by a dedicated
team at Google and is well documented\footnote{\url{https://chromedevtools.github.io/devtools-protocol/}}.
In order to provide as much integration without any additional effort in only makes sense to rely on
a well maintained protocol like this.

When it comes to debugging an HbbTV application there will be always there parties involved. The
instrumentation logic, the backend and the authoring tool. The instrumentation logic is what actually
interacts with the target environment. It executes commands that it receives from the backend and
returns desired information. Since the instrumentation script is not much more than any other script
on the page it can't support all methods that are defined within the Remote Debugging Protocol.
However the JavaScript API is pretty comprehensive and covers the essential requirements of that
protocol like returning and modifying the state of certain properties like DOM nodes. Many things can
be emulated which is sufficient for this use case. It is important to ensure that the instrumentation
script doesn't affect in any way other scripts or the web application in general from bevaing
differently. It has to keep its environment as pristine as possible. As a debugging tool it should
help developers to find bugs and not to create them. Once an instrumentation script was injected
into an environments it has to register itself to the backend. Script and backend establish their
connection via WebSockets. Since events and methods will be exchanged randomly from both sides
it is important to have a full duplex connection type so both ends can communicate with each other
in an asynchronous fashion. To identify the target the instrumentation script has to identify
itself with an unique id that can be either the host of the HbbTV app or a random chosen one. The
backend will register the page based on that id and some other metadata and will manage any
connections to it so that arbitrary clients can connect to the page with the backend as proxy. Due
to some house keeping work the backend will never directly connect a client to the instrumented
page. In fact it will manage the communication with two different WebSocket channels. Not all method
requests from clients are directed to the page itself. All methods of the Remote Debugging Protocol
that relate to network events or page lifecycles are handled by the backend. Figure \ref{fig:command_handling}
shows the activity between all parties in more detail.

\begin{figure}[htb]
  \centering
  \hspace*{-1.3cm}
  \includegraphics[width=17cm]{command_handling.pdf}\\
  \caption{Communication Activity between Instrumentation Script, Backend and Debugging Client}\label{fig:command_handling}
\end{figure}

In scenarios where a full page load happened the instrumentation script looses the connection with
the backend. It manages to reconnect to the target, given that the page unique id is still the same,
and makes sure it propagates the right lifecycle events to the connected clients. They won't recognise
any connection abruption and instead properly handle the page load on their side. In some cases the
response of the instrumentation script needs to be enhanced with data from the backend. This happens
when network data is involved which is only stored on the backend side. A middleware handles this
situation by enhancing the result object before returning it back to the client.

There are two ways to inject the instrumentation script into the target environment. It can be either
placed manually into the page by referencing the script via script tag or the Devtools Backend can be
used as a proxy. In this case it captures all http packages on a certain port (usually port 80) and
injects the script inline into the page automatically. The proxy registers the page to the backend
based on the data it gets from the request. This has the advantage that the application doesn't have
to get modified to instrument it. However running the target device (e.g. the Smart TV) through a
proxy is not always possible. Therefor the component provides a launcher script that can connect to
the backend to register the page before the instrumentiation script gets initited.

Once the instrumentation script was initiated and a remote debugging client connects to the backend
they both exchange JSON payload over the socket channels. The client usually listens to certain
domain events (depending of the use case) and fires methods with an id, a method name containing
the domain and the request (e.g. \textit{CSS.getMatchedStylesForNode}) as well as some parameters
that get propagated to the method (e.g. a node id). Each domain has to get enabled by the debugging
client so that the communication can be reduced to the minimum. If the client would enable all
domains it would overflow the socket channels. This keeps the data amount manageable. The backend
only propagates messages to the instrumentation script if the containing method was enabled by
the client beforehand. Even though all methods and events of the protocol are documented in a
comprehensive way\footnote{see \url{https://chromedevtools.github.io/devtools-protocol/}} the order
of events and methods that have to get triggered on both sides is unknown. The only way to find
out when certain events has to get thrown is by debugging the debugging tool. Since the Chrome
Devtools is just a webapplication itself it is possible to debug it using the Chrome Devtools.
Within the \textit{Timeline} tab it is possible to inspect the WebSocket connection to the browser
in real time. This allows to reverse engineer the protocol and emulate a similar behavior like
in the browser.

\subsection{Appium-HbbTV-Driver\label{sec:appiumhbbtvdriver}}

- How is Appium structured
- base driver
- mjwp
- command lifecycle (uml diagram)
- running emulator

\subsection{Raspberry Pi\label{sec:pi}}

- Why is it used
- Advantages/Disadvantages
- how to be configured
- network graph

\subsection{Selenium Grid\label{sec:grid}}

- What is the Selenium Grid
- Explain role and responsibilities

\section{Continuos Integration and Delivery\label{sec:cicd}}

- What is CI/CD
- Role of CI/CD in software development
- jenkins setup (how to create a job)
